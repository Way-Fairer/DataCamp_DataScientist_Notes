{"cells":[{"source":"# Introduction to NumPy\nRun the hidden code cell below to import the data used in this course.","metadata":{},"id":"ed138f26-a6a8-4176-9055-ae5c3f9f4d7a","cell_type":"markdown"},{"source":"# Importing numpy\nimport numpy as np\n\n# Importing the data\nwith open(\"datasets/rgb_array.npy\", \"rb\") as f:\n    rgb_array = np.load(f)\nwith open(\"datasets/tree_census.npy\", \"rb\") as f:\n    tree_census = np.load(f)\nwith open(\"datasets/monthly_sales.npy\", \"rb\") as f:\n    monthly_sales = np.load(f)\nwith open(\"datasets/sudoku_game.npy\", \"rb\") as f:\n    sudoku_game = np.load(f)\nwith open(\"datasets/sudoku_solution.npy\", \"rb\") as f:\n    sudoko_solution = np.load(f)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false},"executionTime":70,"lastSuccessfullyExecutedCode":"# Importing numpy\nimport numpy as np\n\n# Importing the data\nwith open(\"datasets/rgb_array.npy\", \"rb\") as f:\n    rgb_array = np.load(f)\nwith open(\"datasets/tree_census.npy\", \"rb\") as f:\n    tree_census = np.load(f)\nwith open(\"datasets/monthly_sales.npy\", \"rb\") as f:\n    monthly_sales = np.load(f)\nwith open(\"datasets/sudoku_game.npy\", \"rb\") as f:\n    sudoku_game = np.load(f)\nwith open(\"datasets/sudoku_solution.npy\", \"rb\") as f:\n    sudoko_solution = np.load(f)"},"id":"0e7ac1c4-cd26-412e-84b1-e9f54233225a","cell_type":"code","execution_count":1,"outputs":[]},{"source":"## Take Notes\n\nAdd notes about the concepts you've learned and code cells with code you want to keep.","metadata":{},"id":"d4829b9c-81a4-4d30-9092-2c62486e7b2e","cell_type":"markdown"},{"source":"## Introducing arrays\n\nNumpy is the core libary for scientific computing in Python. Lots of other libaries build off of this.\n\nThe array is the main object in NumPy. It's a grid-like structure that holds data. An array can have any number of dimensions, and each dimension can be any length. You can create arrays from Python by passing a list as an argument to the np.array() function. This will have a data type of numpy.ndarray. a 2D array would be a list of lists, and a list of lists of lists would be 3D.\n","metadata":{},"id":"ace6c307-3d9a-4a1f-986f-7f1de8e04de1","cell_type":"markdown"},{"source":"# Import NumPy\nimport numpy as np\n\n# Convert sudoku_list into an array\nsudoku_array = np.array(sudoku_list)\n\n# Print the type of sudoku_array \nprint(type(sudoku_array))","metadata":{"executionTime":551,"lastSuccessfullyExecutedCode":"# Import NumPy\nimport numpy as np\n\n# Convert sudoku_list into an array\nsudoku_array = np.array(sudoku_list)\n\n# Print the type of sudoku_array \nprint(type(sudoku_array))"},"cell_type":"code","id":"76a97a04-bdaf-4622-b877-70efaae168b0","execution_count":null,"outputs":[{"output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Convert sudoku_list into an array\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m sudoku_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43msudoku_list\u001b[49m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Print the type of sudoku_array \u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(sudoku_array))\n","\u001b[0;31mNameError\u001b[0m: name 'sudoku_list' is not defined"],"ename":"NameError","evalue":"name 'sudoku_list' is not defined"}]},{"source":"Lists can contain different data types, but all the elements in array must be the same data type, so it's very efficient, and takes up less space in memory. \n\nYou can create arrays from scratch using np.zeros(), np.random.random(), and np.arange()\n\nnp.zeros((5,3)) makes an array of zeros, with 5 rows and 3 columns, and you can fill with data later on. A tuple of integers is used as the argument. \n\nnp.random.random((2,4)) also accepts a tuple for the array's shape. Made of random floats between 0 and 1. Called random.random because np.random is a Numpy module for random sampling, and random() is a function within it","metadata":{},"cell_type":"markdown","id":"ad85c8e6-45a4-4cee-aab8-0516df94cb67"},{"source":"# Create an array of zeros which has four columns and two rows\nzero_array = np.zeros((2,4))\nprint(zero_array)\n\n# Create an array of random floats which has six columns and three rows\nrandom_array = np.random.random((3,6))\nprint(random_array)","metadata":{"executionCancelledAt":1678639665347},"cell_type":"code","id":"caa923fc-6dc9-41ab-89a5-53b81830cf94","execution_count":null,"outputs":[]},{"source":"np.arange creats evenly spaced array of numbers based on given start and stop values; creates array of sequential integers. np.arange(-3,4) will return -3, -2, -1, 0, 1, etc. Start value included in output, stop is not. start value can be omitted if range begins with 0. If there's a 3rd argument, that's interpreted as the step value ","metadata":{},"cell_type":"markdown","id":"b57b3c50-32c8-467f-90a9-9766d7bd280b"},{"source":"# Create an array of integers from one to ten\none_to_ten = np.arange(1, 11)\n\n# Create your scatterplot\nplt.scatter(one_to_ten, doubling_array)\nplt.show()","metadata":{"executionCancelledAt":1678639665397},"cell_type":"code","id":"ed7893c8-1cf3-436a-8703-14883aa6ecff","execution_count":null,"outputs":[]},{"source":"## Array dimensionality\n\n*The slides will help with visualizing nD arrays\n\nData saved in higher dimensions can be harder to work with. Instead of making a list of lists of lists, you can create an array of 2D arrays. You can visualize a 3D array as a bunch of 2D arrays with the same shape (like 2 rows and 2 columns) stacked on top of each other.","metadata":{},"cell_type":"markdown","id":"d1ef4f5b-5e77-490b-920c-0d20c65a0ad9"},{"source":"# Create the game_and_solution 3D array\ngame_and_solution = np.array([sudoku_game, sudoku_solution])\n\n# Print game_and_solution\nprint(game_and_solution) ","metadata":{"executionCancelledAt":1678639665429},"cell_type":"code","id":"816a3d1d-c1ad-415a-ae13-321e2ed4aafb","execution_count":null,"outputs":[]},{"source":"\n4D arrays can be harder to visualize since we don't have a 4th dimension; think of it like a 2D array filled with 3D arrays\n","metadata":{},"cell_type":"markdown","id":"abda61cd-d274-49e9-b3f4-744e801af5f6"},{"source":"# Create a second 3D array of another game and its solution \nnew_game_and_solution = np.array([new_sudoku_game, new_sudoku_solution])\n\n# Create a 4D array of both game and solution 3D arrays\ngames_and_solutions = np.array([game_and_solution, new_game_and_solution])\n\n# Print the shape of your 4D array\nprint(games_and_solutions.shape)\n\n# Output is (2, 2, 9, 9), means that there's 2 sets of game/solution pairs, and within each game/solution pair, all arrays have nine rows and nine columns.","metadata":{"executionCancelledAt":1678639665508},"cell_type":"code","id":"24028583-f752-46de-9082-8ab6d4ef0564","execution_count":null,"outputs":[]},{"source":"Arrays can be referred to as vectors, matrices, or tensors; these are more mathematical terms than NumPy terms, they all describe types of arrays. The difference between them is the number of dimensions an array has. \n\nA vector is an array with one dimension. There's no difference between row and column vectors in NumPy since no second axis is specified for 1D arrays (shape of (5,) and shape (5,). If you need an array that is _**explicitly**_ horizontal and vertical, it must be a 2D array so that NumPy understands what axis it lies on (shape(5,1) or shape(1,5)), but they're no vectors anymore. It's a matrix\n\nIn math, a 2D array is a matrix, and an array with 3 or more dimensions is a tensor\n\nArray attributes are properties of an instance of an array:\n- array_name.shape - describes shape and returns tuple with length of each      dimension. Referring to rows and columns only gets us so far in NumPy since many arrays have more than 2 dimentions. Instead of referring to rows, we can refer to the 1st dimension. Instead of referring to columns, we can refer to the 2nd dimension, but it's common to use row and columns terms\n\nArray methods are called directly on the array object itself, rather than passing the array as an argument like we do with NumPy functions like np.array:\n- .flatten() - takes all elements and flattens them into one 1D array\n- .reshape() - redefines the shape of an array without changing the elements    that make up an array. Pass in a tuple of desired row and column numbers;       the number must be compatible with the number of elements in the array","metadata":{},"cell_type":"markdown","id":"ba3d600e-7b62-41da-8c38-f8cbf0544c36"},{"source":"# Flatten sudoku_game\nflattened_game = sudoku_game.flatten()\n\n# Print the shape of flattened_game\nprint(flattened_game.shape)\n\n# Reshape flattened_game back to a nine by nine array\nreshaped_game = flattened_game.reshape((9,9))\n\n# Print sudoku_game and reshaped_game\nprint(sudoku_game)\nprint(reshaped_game)","metadata":{},"cell_type":"code","id":"f2b70b92-e782-47ac-b267-36c5018ba1b4","execution_count":null,"outputs":[]},{"source":"## NumPy data types\n\nNumPy data types are more specific than Python data types in that NumPy data types include both the type of data (like integer or string) and the ammount of memory available in bits (like np.int64). You can save memory by reducing the data type's bitsize when our data doesn't require a large bitsize.\n\nBit is binary digit. Can hold only values of 0 or 1. Smallest unit of memory data available on a computer. A byte is a sequence of 8 bits. np.int32 can store 2 to the 32nd power numbers since this is the number of possible combinations of 0 and 1 available in 32 bits; so it can hold about 4 billion integers, from around -2 billion to 2 billion. Anything outside those bounds need a larger bit size like 64. Booleans don't have a bitsize since Booleans don't vary in size\n\nTo find the data types of an array, use array.dtype. NumPy automatically decides the data type based on the content at array creation, like detecting integers (default bitsize 64 for floats and integers). For strings, NumPy select the data type with capacity large enough for the longest string. <U12 is a Unicode string with max length of 12. ","metadata":{},"cell_type":"markdown","id":"dfeeed49-7fcb-4889-b994-bb8c48c5e199"},{"source":"# Create an array of zeros with three rows and two columns\nzero_array = np.zeros((3, 2))\n\n# Print the data type of zero_array\nprint(zero_array.dtype)\n\n# Create a new array of int32 zeros with three rows and two columns\nzero_int_array = np.zeros((3,2), dtype=np.int32)\n\n# Print the data type of zero_int_array\nprint(zero_int_array.dtype)","metadata":{},"cell_type":"code","id":"18666f73-0afb-425b-9fd6-eb9f7c568af9","execution_count":null,"outputs":[]},{"source":"You can declare a data type at creation using dtype= argument in the np.array() function. You can convert datatypes using array.astype(datatype) method. ","metadata":{},"cell_type":"markdown","id":"a6547efe-17a9-4f15-a5d1-ce56505c9235"},{"source":"# Sudoku games only ever store integers from one to nine\n# So we change its bit size to something smaller, like int8\n# Print the data type of sudoku_game\nprint(sudoku_game.dtype)\n\n# Change the data type of sudoku_game to int8\nsmall_sudoku_game = sudoku_game.astype(np.int8)\n\n# Print the data type of small_sudoku_game\nprint(small_sudoku_game.dtype)","metadata":{},"cell_type":"code","id":"2e2c6ed8-96c7-4a99-8d90-e24fa12adfa4","execution_count":null,"outputs":[]},{"source":"If you try to make an array from a list with several types, Python automatically converts all the values to the same data type, like strings; this is called type coercion. Numbers are easily cast into strings, but strings are not easily cast into numbers while still preserving the original data. \n\nA single string will make Python cast the whole list as strings. Adding a single float to a list of integers will change all the integers to floats, and adding a single integer will convert a list of Booleans to integers\n\nPay attention because element types in your array will change without notice","metadata":{},"cell_type":"markdown","id":"e9c4e9ee-ba79-4426-9476-aab2643f83cc"},{"source":"## Indexing and slicing arrays\n\nFirst index is 0. For indexing in 2D, provide row and column number to index, like sudoku[2,4]. Giving only one index returns the row, and passing :, # outputs all rows and the one column\n\nIn slicing, the element at the start of the slice is included, but the stop value is not. To slice in 2D, you have to provide the row start and stop indices for the rows and columns, like sudoku[3:6, 3:6]\n\nYou could also give NumPy a third number in a slice: the step value. A step value of 2 gives you every other number in the array. You can use step values in both rows and columns, or just one or the other.\n\nnp.sort(array) sorts an array along a given axis. If you just pass np.sort(sudoku), then the values are sorted across the columns, so that low values are on the left and high values on the right. To sort across rows, you need to learn array axis orders...\n\nIn a 2D array, the direction vertically along rows is axis zero (from up to down), and the direct along columns is axis one (left to right). Remember that a column looks like the number one, and that's axis 1. \n\nThe default axis is np.sort() is the last axis of the array passed to it. If a 2D array is being sorted, NumPy sorts by columns, since columns. To sort the array by row, pass the keyword argument axis=0 into np.sort() so that the highest numbers in each row are at the bottom of the array","metadata":{},"cell_type":"markdown","id":"404d1322-9fb7-4559-8851-700cf990f77d"},{"source":"# Select all rows of block ID data from the second column\nblock_ids = tree_census[:, 1]\n\n# Print the first five block_ids\nprint(block_ids[0:5])\n\n# Select the tenth block ID from block_ids\ntenth_block_id = block_ids[9]\nprint(tenth_block_id)\n\n# Select five block IDs from block_ids starting with the tenth ID\nblock_id_slice = block_ids[9:14]\nprint(block_id_slice)","metadata":{},"cell_type":"code","id":"75b40ca5-7d14-44a7-bbfe-ff4e9f438b3a","execution_count":null,"outputs":[]},{"source":"# Create an array of the first 100 trunk diameters from tree_census\nhundred_diameters = tree_census[0:100, 2]\nprint(hundred_diameters)\n\n# Create an array of trunk diameters with even row indices from 50 to 100 inclusive\nevery_other_diameter = tree_census[50:101:2, 2]\nprint(every_other_diameter)","metadata":{},"cell_type":"code","id":"87ea8ced-aa68-4f58-9b36-5d844cec1197","execution_count":null,"outputs":[]},{"source":"# Extract trunk diameters information and sort from smallest to largest\nsorted_trunk_diameters = np.sort(tree_census[:, 2])\nprint(sorted_trunk_diameters)","metadata":{},"cell_type":"code","id":"3a65b258-8800-4b9f-b75a-31244db18257","execution_count":null,"outputs":[]},{"source":"## Filtering Arrays\n\nYou can use masks and fancy indexing, or np.where()\n\nThe code to create a Boolean mask checks whether the condition is true for each element in an array. The mask itself is an array of Booleans the same shape as the evaluated array. To filter an array (one_to_five) that only includes even numbers, first create a Boolean mask of True and False values based on whether the element is evenly divisible by 2, like with the statment mask = one_to_five % 2 == 0. You can then index the array using the mask, like one_to_five[mask]. This is fancy indexing. Useful for when we are interested in the elements that meet a condition. The mask provides the indices of elements that are True\n\nYou may want to filter with a condition in one row or column but return data from another, like returning class ids for even sized classes. You would make a mask like classrooms_id_and_sizes[:, 1] % 2 == 0, which checks all values in the 2nd column for the condition. You would need index the first column using that mask, like classrooms_id_and_sizes[:, 0]","metadata":{},"cell_type":"markdown","id":"eee7d6e2-6de6-4756-a749-5beea877cac5"},{"source":"# Create an array which contains row data on the largest tree in tree_census\n# Tree diameter is saved in column with index 2\nlargest_tree_data = tree_census[tree_census[:, 2] == 51]\nprint(largest_tree_data)\n\n# Slice largest_tree_data to get only the block ID\nlargest_tree_block_id = largest_tree_data[:, 1]\nprint(largest_tree_block_id)\n\n# Create an array which contains row data on all trees with largest_tree_block_id\ntrees_on_largest_tree_block = tree_census[tree_census[:, 1] == largest_tree_block_id]\nprint(trees_on_largest_tree_block)","metadata":{},"cell_type":"code","id":"76fb81fd-2f34-4e85-8e83-33143da21632","execution_count":null,"outputs":[]},{"source":"Fancy indexing returns array of elements which meet a condition. The indices can be used to direct NumPy where to apply code. It can also be used for combining data as well as filtering arrays. I can pull different elements into a new array based on what meets the condition. So with the classroom example, you would do np.where(classroom_ids_sizes[:, 1] % 2 == 0), and it would return (array([0, 3]),). This means classrooms at indices 0 and 3 meet the criteria.\n\nThe np.where() function returns a tuple in parentheses. This is because when the filtered array is multi-dimensional, each element can only be located by including an index for every dimension. So for a 2D array would return (array([0,0,0]), array([0,0,0])), since identifying all the elements would require a row index (first array) and a column index (second array). It's helpful to unpack the results of np.where() into different variables ","metadata":{},"cell_type":"markdown","id":"9fe99f3b-7535-44a5-8223-0f6186af9a73"},{"source":"# Create the block_313879 array containing trees on block 313879\nblock_313879 = tree_census[tree_census[:, 1] == 313879]\nprint(block_313879)","metadata":{},"cell_type":"code","id":"4a27eb05-47b4-4a58-a7b4-3ae18754ca1e","execution_count":null,"outputs":[]},{"source":"# Create an array of row_indices for trees on block 313879\nrow_indices = np.where(tree_census[:, 1] == 313879)\n\n# Create an array which only contains data for trees on block 313879\nblock_313879 = tree_census[row_indices]\nprint(block_313879)","metadata":{},"cell_type":"code","id":"8421cee7-90b2-4384-8eb6-4c2161be9f7a","execution_count":null,"outputs":[]},{"source":"The real power of np.where() is its ability to check whether rows, columns, or elements meet a condition and then pull one element if the condition is met and another if not. So if you wanted to replace all the 0s in the sudoku game with empty strings, you could use np.where(sudoku == 0, '', sudoku), The third argument specifies how to change the element if it does not meet the condition. Since we want the non-zeros to remain unchanged, we're passing off the original array to signify that","metadata":{},"cell_type":"markdown","id":"badbc95c-f0c3-45c0-898d-c90542ef5ddb"},{"source":"# Create and print a 1D array of tree and stump diameters\n# Have to include all the semicolons to specifu that it's all rows in that column\ntrunk_stump_diameters = np.where(tree_census[:, 2] == 0, tree_census[:, 3], tree_census[:, 2])\nprint(trunk_stump_diameters)","metadata":{},"cell_type":"code","id":"ad86ea0b-97ef-42f7-9e09-781f40e4db30","execution_count":null,"outputs":[]},{"source":"## Adding and removing data\n\nConcatenate: add data to an array along any axis. use np.concatenate()\nIf you have named aarays, you can pass a tuple of the array names into np.concatenate(). By default this will concatenate along the first axis, and add rows. For other dimensions (columns), use the keyword axis=\n\nShapes must be compatible; they must have the same shape along all axes except the one being concatenated along. They must also have the same number of dimensions, so you couldn't concatenate a 1D array with a 2D array, even if the row/column sizes where the same. So you would need to use .reshape() on the 1D array to make them compatible. Depending on if the data is vertical or horizontal, set a value of 1 in the reshape tuple argrument as the length of the flat dimension. So if you have a 1D array with 3 rows, use array_1D.reshape((3,1)). You can't add new dimensions with concatenate; it only adds data along an existing axis","metadata":{},"cell_type":"markdown","id":"40519111-9a3e-44c0-8541-9c1f41909ee9"},{"source":"# Print the shapes of tree_census and new_trees\nprint(tree_census.shape, new_trees.shape)\n\n# Add rows to tree_census which contain data for the new trees\nupdated_tree_census = np.concatenate((tree_census, new_trees))\nprint(updated_tree_census)","metadata":{},"cell_type":"code","id":"bd3b6cc8-24b4-4329-841c-feb0d38a2a43","execution_count":null,"outputs":[]},{"source":"# Print the shapes of tree_census and trunk_stump_diameters\nprint(trunk_stump_diameters.shape, tree_census.shape)\n\n# Reshape trunk_stump_diameters\nreshaped_diameters = trunk_stump_diameters.reshape((1000, 1))\n\n# Concatenate reshaped_diameters to tree_census as the last column\nconcatenated_tree_census = np.concatenate((tree_census, reshaped_diameters), axis=1)\nprint(concatenated_tree_census)","metadata":{},"cell_type":"code","id":"b8ec6177-0075-41d9-a7ad-8adeb80a7113","execution_count":null,"outputs":[]},{"source":"np.delete() takes 3 arguments: the array to delete from; a slice, index, or array of indices to be deleted; and the axis to be deleted along. If you want to delete the second row from a 2D array: np.delete(classroom_date, 1, axis=0), a column would use axis=1. If no axis is specified, Numpy deletes the indicated index/indices along a flattened version of the array. ","metadata":{},"cell_type":"markdown","id":"64026117-d962-4b1b-aa68-82fa3f6b3379"},{"source":"# Delete the stump diameter column from tree_census\ntree_census_no_stumps = np.delete(tree_census, 3, axis=1)\n\n# Save the indices of the trees on block 313879\nprivate_block_indices = np.where(tree_census_no_stumps[:, 1] == 313879)\n\n# Delete the rows for trees on block 313879 from tree_census_no_stumps\ntree_census_clean = np.delete(tree_census_no_stumps, private_block_indices, axis=0)\n\n# Print the shape of tree_census_clean\nprint(tree_census_clean.shape)","metadata":{},"cell_type":"code","id":"9d6a8ded-a3de-46db-9d19-eda646d7dcb8","execution_count":null,"outputs":[]},{"source":"## Summarizing data\n\nAggregating methods: .sum(), .min(), .max(), .mean(), .cumsum()\n\nCalling these methods on an array would calculate over the whole array. You can add an axis= argument to define which axis to sum across. axis=0 would sum across all rows in each column and would return an array with the results, the number of elements in the array being the number of columns. The axis listed in the axis= argument refers to the axis we want collapsed\n\nkeepdims= is an optional argument in the .sum(), .min(), .max(), .mean() methods. If set to True, then the dimensions that are collapsed when aggregating are left in the output array and set to one. For instance, if axis=1 and dimension is 2D, then the output would be in a 2D column format. This can help with dimension compatibility \n\n.cumsum() will provide a cummulative sum of elements along a given axis. IF axis= 0, cummulative sum would be calculated down each row, and the bottom row would have the final cummulative sum\n\nGraphs are helpful with communicating summary information","metadata":{},"cell_type":"markdown","id":"0e92f5e5-1495-4be5-901e-5f7d9f840e77"},{"source":"# Create a 2D array of total monthly sales across industries\nmonthly_industry_sales = monthly_sales.sum(axis=1, keepdims=True)\nprint(monthly_industry_sales)\n\n# Add this column as the last column in monthly_sales\nmonthly_sales_with_total = np.concatenate((monthly_sales, monthly_industry_sales), axis=1)\nprint(monthly_sales_with_total)","metadata":{},"cell_type":"code","id":"85482414-75ed-4a7b-9636-ef3d4a9fd615","execution_count":null,"outputs":[]},{"source":"# Create the 1D array avg_monthly_sales\navg_monthly_sales = monthly_sales.mean(axis=1)\nprint(avg_monthly_sales)\n\n# Plot avg_monthly_sales by month\nplt.plot(np.arange(1,13), avg_monthly_sales, label=\"Average sales across industries\")\n\n# Plot department store sales by month\nplt.plot(np.arange(1,13), monthly_sales[:, 2], label=\"Department store sales\")\nplt.legend()\nplt.show()","metadata":{},"cell_type":"code","id":"952e226b-da24-409f-a1ab-3f90aee5fd63","execution_count":null,"outputs":[]},{"source":"# Find cumulative monthly sales for each industry\ncumulative_monthly_industry_sales = monthly_sales.cumsum(axis=0)\nprint(cumulative_monthly_industry_sales)\n\n# Plot each industry's cumulative sales by month as separate lines\nplt.plot(np.arange(1, 13), cumulative_monthly_industry_sales[:, 0], label=\"Liquor Stores\")\nplt.plot(np.arange(1, 13), cumulative_monthly_industry_sales[:, 1], label=\"Restaurants\")\nplt.plot(np.arange(1, 13), cumulative_monthly_industry_sales[:, 2], label=\"Department stores\")\nplt.legend()\nplt.show()","metadata":{},"cell_type":"code","id":"92952bb1-7e80-4a22-a3d9-03d736eb4299","execution_count":null,"outputs":[]},{"source":"## Vectorized operations\n\nWhen elements are summed in an array, it addes them all at once. Since the array will have the same data type, NumPy uses C (very efficient memory usage and speedy). Also reduces the amount of code you need to write.  This is vectorization. \n\nIf you add a single number to an array, it will add that number to all elements; that single number is a scalar. You can also multiply. If you have arrays of the same shape, you add two arrays together like array_a + array_b, it will add the elements together and output an array of the same shape. Same with multiplying, subtracting, and dividing. \n\nWe use vectorized operations for stuff like making Boolean masks and filtering arrays\n\nYou can create your own vectorized functions from Python functions using np.vectorize(). If you have an array of strings and want to check if any lengths are greater than two, you couldn't use len(array) > 2; you would get one True value if there's mone than 2 elements in the array. len() is a Python function, not a NumPy function, so it can't vectorize. If you feed len (no trailing parentheses) into np.vectorize() and assign to a variable, then passing the array as an argument into the variable followed by the condition will give you Boolean array","metadata":{},"cell_type":"markdown","id":"39ab536a-ffb7-4a58-89b5-b4cfe85127f4"},{"source":"# .upper() is a string method, meaning that it must be called on an instance of a string: str.upper()\n\n# Vectorize the .upper() string method\nvectorized_upper = np.vectorize(str.upper)\n\n# Apply vectorized_upper to the names array\nuppercase_names = vectorized_upper(names)\nprint(uppercase_names)","metadata":{},"cell_type":"code","id":"bb43c70a-93cd-42a2-b51b-fd81f5ac470c","execution_count":null,"outputs":[]},{"source":"## Broadcasting\n\nRemember that 1D arrays are presented as a row of data by default; to express in a column you must reshape to add (n, 1) so it's one column\n\nTakes vectorized operations to the next level. Stretches a smaller across a larger one, letting you do operations between arrays of different shapes; broadcasting also refers to this type of aray math. Adding a scalar to an array uses broadcasting, essentially creating an array the same size as the original array filled in with the scalar value. \n\nOnly works with compatible arrays. Compare the arrays from right to left. A set of dimensions is compatible when one of them is 1, or they are equal; this must be the case with all dimension sets. A (10, 5) and (5, ) (which is a row of 5 as a 1D array) are broadcastable, because the 1D array's rightmost dimensions are both 5(there's only 1 dimension, so that one dimension is considered the right-most) (but (10, 5) and (10, ) arrays wouldn't be compatible); the arrays don't need to have the same number of dimensions\n\nA 1D array is broadcastable because NumPy operates as thought there's a copy of the 1D array for each row of the 2D array, then operates on them as necessary. NumPy assumes that the user is trying to broadcast row-wise. You could also use .reshape() to convert a 1D array into a 2D array (like (2, ) --> (2, 1)) that can be broadcastable, as long as the leading dimensions meet the broadcasting criteria","metadata":{},"cell_type":"markdown","id":"81441598-7c9b-456d-84e0-17f3c478bafc"},{"source":"## Saving and loading arrays\n\nrgd array: a type of 3d array used in image-based machine learning. Each 1D in the 3D array contains red, green, and blue values, respectively, which together describe the color of a single pixel. The 2D array comprised of 1D arrays represents a row of pixel colors. 255 seems to be the highest number. A 1D array of all 255 is white\n\nArrays can be saved as .csv, .txt, pickle files, etc. NumPy's .npy is the best for speed and storage efficiency\n\nLoad a .npy file: with open(\"file.npy\", 'rb') as f:\narray_name = np.load(f)\nplt.imshow(array_name)\nplt.show()\n\nopen() arguments are the name of the file to open, and the mode to open the file in ('rb' is read binary)\n\nnp.load() takes the alias of the opened .npy file\n\nIn this 3D array, you can slice the array to select all of the first, second, and third components of the 1D arrays, which correspond to the red, blue, and green values, and save them as array representing the three colors like this, which results in 2D arrays: \n\nred_array = logo_rgb_array[:, :, 0]\nblue_array = logo_rgb_array[:, :, 1]\ngreen_array = logo_rgb_array[:, :, 2]\n\nPrinting the top row of each 2D array, you can look at the values across the arrays to figure out what color parts of the first row are. You can use np.where() to replace values and change the color of the images. 255 is often associated with brighter colors, and lower numbers are associated with darker colors\n\ndark_logo_array = np.where(logo_rgd_array == 255, 50, logo_rgb_array)\n\nTo save a array as .npy:\n\nwith open('dark_logo.npy', 'wb') as f:\n    np.save(f, dark_logo_array)\n\nBut this time you use \"wb\" for write binary","metadata":{},"cell_type":"markdown","id":"59e84873-2e4e-47ac-b73b-3cceec0629fc"},{"source":"## Array acrobatics\n\nRearranging data by flipping the order of array elements and changing axis order\n\nIn machine learning, data augmentation is the process of adding additional data by performing small manipulations on data that is already available. You augment data to flip images and use both the flipped and original images to train the model\n\nnp.flip() reverses the order of array elements, along every axis by default. The first axis, the ordered row of pixels, is flipped so that bottom rows are now at top. The second axis (the ordered columns of pixels) so that columns that were on the left are now on the right. The RGB values in the third axis are also flipped so blue is replaced with red, and vice versa (but greens in the middle so it stays the same). \n\nYou can flip along a specific axis to flip by specifying an axis using axis=. Use a tuple to specify multiple axes\n\nWith a 2D array of floats, the np.flip() function will reverse element order along both axes since no axis keyword argument is passed (the shape of the array stays the same, with the last array showing first and the elements when all arrays being reversed). np.transpose() flips axis order while keeping the element order within each axis the same (the shape reverses, where the first element in each 1D array shows up in the first 1D array; columns become rows, and vice versa)\n\nThe default behavior for transpose is to reverse the axis order; you can also specify a custom axis order using the axes= keyword argument. For instance, axes=(1, 0, 2) will make column values into row values and row values into column values, because it changes the axis order from 0, 1, 2 to 1, 0, 2. The third axis will be in the same position","metadata":{},"cell_type":"markdown","id":"5cfd25d2-5bcc-4368-b1cd-6ea843c10839"},{"source":"## Stacking and splitting\n\nYou can unpack arrays using np.split, a function that accepts 3 arguments: the array to split, the number of equally sized arrays desired after the split, and the axis to split along. np.split allows multiple assignment, so you can so you can assign the split arrays to multiple variables. The resulting arrays have the same number of dimensions as the original array. If the resulting array has a dimension with a length of one (a tailing dimension), you might remove this dimension using .reshape() method\n\nWith concatenate, we are not able to concatenate data into a new dimension, but you can use np.stack to do it. You can use slice or split to unpack an array, and then use.npstack() to put it back together once you're done with the changes. np.stack() takes the list of arrays you want to stack, and the axis should be set to 2 to make a 3D array\n\nYou can plot 2D data pulled from a 3D array, because some images (like glack and white) are 2D\n\nMatplotlib's default colormap is called Viridis. It's like grayscale but more readable for people with coloblindness. Yellow = lighter values, purple= darker values\n\nnp.stack requires that all arrays have the same shape and number of dimensions, so you may need to reshape the arrays. For the axis argument, the axis should be set to 2 (the last axis) because plt.imshow() requires 3D RGB arrays to have a shape that corresponds to the pixel width and height of the image in the first 2 dimensions, with the RGB values in the third dimension ","metadata":{},"cell_type":"markdown","id":"e346376f-7441-4492-bda2-a618c15413f1"},{"source":"### Tuple\n\nA tuple is a Python data type used to store collections of data, like a list. Created with parentheses","metadata":{},"cell_type":"markdown","id":"f7dcf4c1-c243-4411-ad09-9fecc087e8f7"},{"source":"## Axes\n\nThe first axis is represented by 0, and is along the rows. \n\nThe second axis is represented by 1, and is along the columns; think how columns look like 1s","metadata":{},"cell_type":"markdown","id":"fe9354a2-0f98-428a-9d64-d7a67dcd9ab2"},{"source":"## Trailiing/Rightmost Dimensions\n\nThis answer in StackOverflow helps:https://stackoverflow.com/questions/11178179/numpy-array-broadcasting-rules\n\nRelates to when broadcasting with arrays of different dimensions. If you have two arrays with different dimensions number, say one 1x2x3 and other 2x3, then you compare only the trailing common dimensions, in this case 2x3. But if both your arrays are two-dimensional, then their corresponding sizes have to be either equal or one of them has to be 1.\n\nSo with the example in the class of (10, 5) and (5, ), the second array is a 1D, and the first is a 2D. Since the the most right hand dimension of the 1D array is 5, and the rightmost dimension of the 2D is also 5, making them compatible\n\nBecause the arrays are different sizes, even though the nrow/column numbers don't appear to match across the arrays, the arrays will be set up differently. ","metadata":{},"cell_type":"markdown","id":"dea803f5-8fee-4313-b713-b36d64ea7696"},{"source":"## Help function\n\nhelp(np.unique) for a function\nhelp(np.ndarray.flatten) for a method, where you prefix it with the object type that the method is called on - in this case, a NumPy n-dimensional array","metadata":{},"cell_type":"markdown","id":"41e369fe-b875-4da8-965f-2e4aaba602d7"},{"source":"### Slicing a 3D array\n\nIn the example in the course, to return each first 1D element for a 3D array (splitting the RGB array into red, blue, green), you set the axis=2 in np.split(). I think this is because it's kind of splitting the columns through the array of arrays of arrays\n\nhttps://towardsdatascience.com/a-visual-guide-to-multidimensional-numpy-array-aggregation-97a8960b3c59\n\nWhen adding dimensions, the new, highest dimension is 0, and the other dimensions are increased by 1. So in a 3D array, 0 is the relationship between the two 2D arrays, rows become the 1st dimension, and columns become the 2nd dimension, which is why you you axis=2 to split by columns!!!!!!!!","metadata":{},"cell_type":"markdown","id":"de8600fb-aa9d-404a-936d-7da762a4af93"}],"metadata":{"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"editor":"DataCamp Workspace"},"nbformat":4,"nbformat_minor":5}